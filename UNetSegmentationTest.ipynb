{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import signal\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import argparse\n",
    "from Unet import Generic_UNet, InitWeights_He\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from collections import OrderedDict\n",
    "from numpy.linalg import inv\n",
    "from utilities import SoftDiceLoss, resize_segmentation, _concat, _concatmodel, ComputMetric\n",
    "from sampling_multiprocess import get_augment_par\n",
    "from common_test_Unet import pad_nd_image, _compute_steps_for_sliding_window, getallbatch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testmap(model, saveresults, name, pathname = None, ImgsegmentSize = [80, 160, 160], deepsupervision=False, \n",
    "    DatafileValFoldtr=None, DatafileValFoldts=None, tta=False, ttalist=[0], NumsClass = 2, ttalistprob=[1]):\n",
    "    \n",
    "    batch_size = 1\n",
    "    NumsInputChannel = 1\n",
    "\n",
    "    DatafiletsFold = DatafileValFoldts\n",
    "    DatafiletsImgc1 = DatafiletsFold + 'Imgpre-eval.txt'\n",
    "    DatafiletsLabel = DatafiletsFold + 'seg-eval.txt'\n",
    "    DatafiletsMask = DatafiletsFold + 'mask-eval.txt'\n",
    "\n",
    "    Imgfiletsc1 = open(DatafiletsImgc1)\n",
    "    Imgreadtsc1 = Imgfiletsc1.read().splitlines()\n",
    "    if os.path.isfile(DatafiletsMask):\n",
    "        Masktsfile = open(DatafiletsMask)\n",
    "        Masktsread = Masktsfile.read().splitlines()\n",
    "        Maskread = Masktsread\n",
    "    Labeltsfile = open(DatafiletsLabel)\n",
    "    Labeltsread = Labeltsfile.read().splitlines()\n",
    "\n",
    "    Imgreadc1 = Imgreadtsc1\n",
    "    Labelread = Labeltsread\n",
    "    \n",
    "    DSClist = []\n",
    "    \n",
    "    for numr in range(len(Imgreadc1)):\n",
    "\n",
    "        Imgnamec1 = Imgreadc1[numr]\n",
    "        Imgloadc1 = nib.load(Imgnamec1)\n",
    "        Imgc1 = Imgloadc1.get_fdata()\n",
    "        \n",
    "        if os.path.isfile(DatafiletsMask):\n",
    "            Maskname = Maskread[numr]\n",
    "            Maskload = nib.load(Maskname)\n",
    "            roi_mask = Maskload.get_fdata()\n",
    "        Labelname = Labelread[numr]\n",
    "        Labelload = nib.load(Labelname)\n",
    "        gtlabel = Labelload.get_fdata()\n",
    "        \n",
    "        Imgc1 = np.float32(Imgc1)\n",
    "\n",
    "        knamelist = Imgnamec1.split(\"/\")\n",
    "        kname = knamelist[-2]\n",
    "\n",
    "        channels = Imgc1[None, ...]\n",
    "\n",
    "        from common_test_Unet import tta_rolling\n",
    "        hp_results = tta_rolling(model, channels, batch_size, ImgsegmentSize, NumsInputChannel, NumsClass, tta, ttalist, ttalistprob, deepsupervision)\n",
    "\n",
    "        ## use the mask to constratin the results\n",
    "        if os.path.isfile(DatafiletsMask):\n",
    "            PredSegmentationWithinRoi = hp_results * roi_mask\n",
    "        else:\n",
    "            PredSegmentationWithinRoi = hp_results\n",
    "        # PredSegmentationWithinRoi = predSegmentation\n",
    "\n",
    "        predlabel = np.argmax(PredSegmentationWithinRoi, axis=0)\n",
    "\n",
    "        if NumsClass == 2:\n",
    "            labelwt = gtlabel == 1\n",
    "            predwt = predlabel == 1\n",
    "    \n",
    "            DSCwt, SENSwt, PRECwt = ComputMetric(labelwt, predwt)\n",
    "    \n",
    "            # print(DSCwt)\n",
    "            DSClist.append([DSCwt])\n",
    "        else:\n",
    "            labelc1 = gtlabel == 1\n",
    "            predc1 = predlabel == 1\n",
    "            labelc2 = gtlabel == 2\n",
    "            predc2 = predlabel == 2\n",
    "            labelc3 = gtlabel == 3\n",
    "            predc3 = predlabel == 3\n",
    "    \n",
    "            DSCc1, SENSc1, PRECc1 = ComputMetric(labelc1, predc1)\n",
    "            DSCc2, SENSc2, PRECc2 = ComputMetric(labelc2, predc2)\n",
    "            DSCc3, SENSc3, PRECc3 = ComputMetric(labelc3, predc3)\n",
    "    \n",
    "            # print(DSCwt)\n",
    "            DSClist.append([DSCc1, DSCc2, DSCc3])\n",
    "        \n",
    "        for kcls in range(PredSegmentationWithinRoi.shape[0]):\n",
    "\n",
    "            imgToSave = PredSegmentationWithinRoi[kcls, :, :, :]\n",
    "\n",
    "            if saveresults:\n",
    "                npDtype = np.dtype(np.float32)\n",
    "                hdr_origin = Imgloadc1.header\n",
    "                affine_origin = Imgloadc1.affine\n",
    "                \n",
    "                newLabelImg = nib.Nifti1Image(imgToSave, affine_origin)\n",
    "                newLabelImg.set_data_dtype(npDtype)\n",
    "\n",
    "                dimsImgToSave = len(imgToSave.shape)\n",
    "                newZooms = list(hdr_origin.get_zooms()[:dimsImgToSave])\n",
    "                if len(newZooms) < dimsImgToSave:  # Eg if original image was 3D, but I need to save a multi-channel image.\n",
    "                    newZooms = newZooms + [1.0] * (dimsImgToSave - len(newZooms))\n",
    "                newLabelImg.header.set_zooms(newZooms)\n",
    "\n",
    "                directory = \"./output/%s/%s/\" % (pathname, name)\n",
    "                if not os.path.exists(directory):\n",
    "                    os.makedirs(directory)\n",
    "                savename = directory + 'pred_' + kname + 'cls' + str(kcls) + '_prob.nii.gz'\n",
    "                nib.save(newLabelImg, savename)\n",
    "    \n",
    "    DSCmean = np.array(DSClist)\n",
    "    DSCmean = DSCmean.mean(axis=0)\n",
    "    print(DSCmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostateckpt = './checkpoints_seg/Prostate/3DUNet_vanilla_Prostate_det/checkpoint.pth.tar'\n",
    "atlasckpt = './checkpoints_seg/ATLAS/3DUNet_vanilla_ATLAS_det/checkpoint.pth.tar'\n",
    "atlasckpt_ci1 = './checkpoints_seg/ATLAS/3DUNet_asymargin_1_ATLAS_det/checkpoint.pth.tar'\n",
    "atlasckpt_ci2 = './checkpoints_seg/ATLAS/3DUNet_asyfocal_4_ATLAS_det/checkpoint.pth.tar'\n",
    "atlasckpt_rl1 = './checkpoints_seg/ATLAS/3DUNet_mixup_ATLAS_det/checkpoint.pth.tar'\n",
    "atlasckpt_rl2 = './checkpoints_seg/ATLAS/3DUNet_GIN_ATLAS_det/checkpoint.pth.tar'\n",
    "cardiacckpt = './checkpoints_seg/Cardiac/3DUNet_vanilla_Cardiac_det/checkpoint.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostatevalpath = './data/datafile/Dataset_Prostate/BMCval/'\n",
    "prostatetestpath = './data/datafile/Dataset_Prostate/BMCtest/'\n",
    "prostatetestpath1 = './data/datafile/Dataset_Prostate/BIDMC/'\n",
    "prostatetestpath2 = './data/datafile/Dataset_Prostate/HK/'\n",
    "prostatetestpath3 = './data/datafile/Dataset_Prostate/I2CVB/'\n",
    "prostatetestpath4 = './data/datafile/Dataset_Prostate/RUNMC/'\n",
    "prostatetestpath5 = './data/datafile/Dataset_Prostate/UCL/'\n",
    "prostatetestpaths = [prostatetestpath1, prostatetestpath2, prostatetestpath3, prostatetestpath4, prostatetestpath5]\n",
    "#\n",
    "atlasvalpath = './data/datafile/Dataset_Brain_lesion/Siemens Trioval/'\n",
    "atlastestpath = './data/datafile/Dataset_Brain_lesion/Siemens Triotest/'\n",
    "atlastestpath1 = './data/datafile/Dataset_Brain_lesion/GE 750 Discovery/'\n",
    "atlastestpath2 = './data/datafile/Dataset_Brain_lesion/GE Signa Excite/'\n",
    "atlastestpath3 = './data/datafile/Dataset_Brain_lesion/GE Signa HD-X/'\n",
    "atlastestpath4 = './data/datafile/Dataset_Brain_lesion/Philips/'\n",
    "atlastestpath5 = './data/datafile/Dataset_Brain_lesion/Philips Achieva/'\n",
    "atlastestpath6 = './data/datafile/Dataset_Brain_lesion/Siemens Allegra/'\n",
    "atlastestpath7 = './data/datafile/Dataset_Brain_lesion/Siemens Magnetom Skyra/'\n",
    "atlastestpath8 = './data/datafile/Dataset_Brain_lesion/Siemens Prisma/'\n",
    "atlastestpath9 = './data/datafile/Dataset_Brain_lesion/Siemens Skyra/'\n",
    "atlastestpath10 = './data/datafile/Dataset_Brain_lesion/Siemens Sonata/'\n",
    "atlastestpath11 = './data/datafile/Dataset_Brain_lesion/Siemens TrioTim/'\n",
    "atlastestpath12 = './data/datafile/Dataset_Brain_lesion/Siemens Verio/'\n",
    "atlastestpath13 = './data/datafile/Dataset_Brain_lesion/Siemens Vision/'\n",
    "atlastestpaths = [atlastestpath1, atlastestpath2, atlastestpath3, atlastestpath4, atlastestpath5, \n",
    "                 atlastestpath6, atlastestpath7, atlastestpath8, atlastestpath9, atlastestpath10, \n",
    "                 atlastestpath11, atlastestpath12, atlastestpath13]\n",
    "#\n",
    "cardiacvalpath = './data/datafile/Dataset_Cardiac/1val/'\n",
    "cardiactestpath = './data/datafile/Dataset_Cardiac/1test/'\n",
    "cardiactestpath1 = './data/datafile/Dataset_Cardiac/2/'\n",
    "cardiactestpath2 = './data/datafile/Dataset_Cardiac/3/'\n",
    "cardiactestpath3 = './data/datafile/Dataset_Cardiac/4/'\n",
    "cardiactestpath4 = './data/datafile/Dataset_Cardiac/5/'\n",
    "cardiactestpaths = [cardiactestpath1, cardiactestpath2, cardiactestpath3, cardiactestpath4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'prostateval'\n",
    "savedckpt = prostateckpt\n",
    "patch_size = [64, 64, 32]\n",
    "testlist = [0]\n",
    "testprob = [1]\n",
    "NumsInputChannel = 1\n",
    "NumsClass = 2\n",
    "pathname = 'prostate'\n",
    "DatafileValFoldtr = None\n",
    "DatafileValFoldts = prostatevalpath\n",
    "#\n",
    "args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "conv_op = nn.Conv3d\n",
    "dropout_op = nn.Dropout3d\n",
    "norm_op = nn.InstanceNorm3d\n",
    "conv_per_stage = 2\n",
    "base_num_features = args['features']\n",
    "args['features'] = base_num_features\n",
    "\n",
    "norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "net_nonlin = nn.LeakyReLU\n",
    "net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "net_num_pool_op_kernel_sizes = []\n",
    "net_num_pool_op_kernel_sizes.append([2, 2, 1])\n",
    "for kiter in range(0, args['downsampling'] - 1):  # (0,5)\n",
    "    net_num_pool_op_kernel_sizes.append([2, 2, 2])\n",
    "net_conv_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling'] + 1):  # (0,6)\n",
    "    net_conv_kernel_sizes.append([3, 3, 3])\n",
    "\n",
    "model = Generic_UNet(NumsInputChannel, base_num_features, NumsClass,\n",
    "                     len(net_num_pool_op_kernel_sizes),\n",
    "                     conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                     dropout_op_kwargs,\n",
    "                     net_nonlin, net_nonlin_kwargs, args['deepsupervision'], False, lambda x: x, InitWeights_He(1e-2),\n",
    "                     net_num_pool_op_kernel_sizes, net_conv_kernel_sizes, False, True, True)\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args['gpu'])\n",
    "if args['resume']:\n",
    "    if os.path.isfile(args['resume']):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args['resume']))\n",
    "        checkpoint = torch.load(args['resume'], map_location='cuda:' + str(args['gpu']))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args['resume'], checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args['resume']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## test condition x 83\n",
    "DatafileValFoldts = prostatetestpath\n",
    "for k in tqdm(range(1,84)):\n",
    "    savename = 'prostatetestsyn_' + str(k) \n",
    "    testlist = [k]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on 5 other domains\n",
    "testlist = [0]\n",
    "for prostatetestpath in tqdm(prostatetestpaths):\n",
    "    DatafileValFoldts = prostatetestpath\n",
    "    savename = 'prostatetest_' + prostatetestpath.split('/')[-2]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'cardiacval'\n",
    "savedckpt = cardiacckpt\n",
    "patch_size = [128, 128, 8]\n",
    "testlist = [0]\n",
    "testprob = [1]\n",
    "NumsInputChannel = 1\n",
    "NumsClass = 4\n",
    "pathname = 'cardiac'\n",
    "DatafileValFoldtr = None\n",
    "DatafileValFoldts = cardiacvalpath\n",
    "#\n",
    "args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "conv_op = nn.Conv3d\n",
    "dropout_op = nn.Dropout3d\n",
    "norm_op = nn.InstanceNorm3d\n",
    "conv_per_stage = 2\n",
    "base_num_features = args['features']\n",
    "args['features'] = base_num_features\n",
    "\n",
    "norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "net_nonlin = nn.LeakyReLU\n",
    "net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "net_num_pool_op_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling']):  # (0,5)\n",
    "    net_num_pool_op_kernel_sizes.append([2, 2, 1])\n",
    "net_conv_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling'] + 1):  # (0,6)\n",
    "    net_conv_kernel_sizes.append([3, 3, 3])\n",
    "\n",
    "model = Generic_UNet(NumsInputChannel, base_num_features, NumsClass,\n",
    "                     len(net_num_pool_op_kernel_sizes),\n",
    "                     conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                     dropout_op_kwargs,\n",
    "                     net_nonlin, net_nonlin_kwargs, args['deepsupervision'], False, lambda x: x, InitWeights_He(1e-2),\n",
    "                     net_num_pool_op_kernel_sizes, net_conv_kernel_sizes, False, True, True)\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args['gpu'])\n",
    "if args['resume']:\n",
    "    if os.path.isfile(args['resume']):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args['resume']))\n",
    "        checkpoint = torch.load(args['resume'], map_location='cuda:' + str(args['gpu']))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args['resume'], checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args['resume']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## test condition x 83\n",
    "DatafileValFoldts = cardiactestpath\n",
    "for k in tqdm(range(1,84)):\n",
    "    savename = 'cardiactestsyn_' + str(k) \n",
    "    testlist = [k]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on 4 other domains\n",
    "testlist = [0]\n",
    "for cardiactestpath in tqdm(cardiactestpaths):\n",
    "    DatafileValFoldts = cardiactestpath\n",
    "    savename = 'cardiactest_' + cardiactestpath.split('/')[-2]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'atlasval'\n",
    "savedckpt = atlasckpt\n",
    "patch_size = [128, 128, 128]\n",
    "testlist = [0]\n",
    "testprob = [1]\n",
    "NumsInputChannel = 1\n",
    "NumsClass = 2\n",
    "pathname = 'atlas'\n",
    "DatafileValFoldtr = None\n",
    "DatafileValFoldts = atlasvalpath\n",
    "#\n",
    "args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args['gpu'])\n",
    "# create model\n",
    "conv_op = nn.Conv3d\n",
    "dropout_op = nn.Dropout3d\n",
    "norm_op = nn.InstanceNorm3d\n",
    "conv_per_stage = 2\n",
    "base_num_features = args['features']\n",
    "args['features'] = base_num_features\n",
    "\n",
    "norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "net_nonlin = nn.LeakyReLU\n",
    "net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "net_num_pool_op_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling']):  # (0,5)\n",
    "    net_num_pool_op_kernel_sizes.append([2, 2, 2])\n",
    "net_conv_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling'] + 1):  # (0,6)\n",
    "    net_conv_kernel_sizes.append([3, 3, 3])\n",
    "\n",
    "model = Generic_UNet(NumsInputChannel, base_num_features, NumsClass,\n",
    "                     len(net_num_pool_op_kernel_sizes),\n",
    "                     conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                     dropout_op_kwargs,\n",
    "                     net_nonlin, net_nonlin_kwargs, args['deepsupervision'], False, lambda x: x, InitWeights_He(1e-2),\n",
    "                     net_num_pool_op_kernel_sizes, net_conv_kernel_sizes, False, True, True)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "if args['resume']:\n",
    "    if os.path.isfile(args['resume']):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args['resume']))\n",
    "        checkpoint = torch.load(args['resume'], map_location='cuda:' + str(args['gpu']))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args['resume'], checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args['resume']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## test condition x 83\n",
    "for k in tqdm(range(1,84)):\n",
    "    savename = 'atlastestcondition_' + str(k) \n",
    "    testlist = [k]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 10, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test on other domains\n",
    "testlist = [0]\n",
    "for atlastestpath in tqdm(atlastestpaths):\n",
    "    DatafileValFoldts = atlastestpath\n",
    "    savename = 'atlastest_' + atlastestpath.split('/')[-2]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATLAS, ci_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'atlasval'\n",
    "savedckpt = atlasckpt_ci1\n",
    "patch_size = [128, 128, 128]\n",
    "testlist = [0]\n",
    "testprob = [1]\n",
    "NumsInputChannel = 1\n",
    "NumsClass = 2\n",
    "pathname = 'atlas_ci1'\n",
    "DatafileValFoldtr = None\n",
    "DatafileValFoldts = atlasvalpath\n",
    "#\n",
    "args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args['gpu'])\n",
    "# create model\n",
    "conv_op = nn.Conv3d\n",
    "dropout_op = nn.Dropout3d\n",
    "norm_op = nn.InstanceNorm3d\n",
    "conv_per_stage = 2\n",
    "base_num_features = args['features']\n",
    "args['features'] = base_num_features\n",
    "\n",
    "norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "net_nonlin = nn.LeakyReLU\n",
    "net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "net_num_pool_op_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling']):  # (0,5)\n",
    "    net_num_pool_op_kernel_sizes.append([2, 2, 2])\n",
    "net_conv_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling'] + 1):  # (0,6)\n",
    "    net_conv_kernel_sizes.append([3, 3, 3])\n",
    "\n",
    "model = Generic_UNet(NumsInputChannel, base_num_features, NumsClass,\n",
    "                     len(net_num_pool_op_kernel_sizes),\n",
    "                     conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                     dropout_op_kwargs,\n",
    "                     net_nonlin, net_nonlin_kwargs, args['deepsupervision'], False, lambda x: x, InitWeights_He(1e-2),\n",
    "                     net_num_pool_op_kernel_sizes, net_conv_kernel_sizes, False, True, True)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "if args['resume']:\n",
    "    if os.path.isfile(args['resume']):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args['resume']))\n",
    "        checkpoint = torch.load(args['resume'], map_location='cuda:' + str(args['gpu']))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args['resume'], checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args['resume']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test condition x 83\n",
    "for k in tqdm(range(1,84)):\n",
    "    savename = 'atlastestcondition_' + str(k) \n",
    "    testlist = [k]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 10, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on other domains\n",
    "testlist = [0]\n",
    "for atlastestpath in tqdm(atlastestpaths):\n",
    "    DatafileValFoldts = atlastestpath\n",
    "    savename = 'atlastest_' + atlastestpath.split('/')[-2]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATLAS, ci_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'atlasval'\n",
    "savedckpt = atlasckpt_ci2\n",
    "patch_size = [128, 128, 128]\n",
    "testlist = [0]\n",
    "testprob = [1]\n",
    "NumsInputChannel = 1\n",
    "NumsClass = 2\n",
    "pathname = 'atlas_ci2'\n",
    "DatafileValFoldtr = None\n",
    "DatafileValFoldts = atlasvalpath\n",
    "#\n",
    "args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args['gpu'])\n",
    "# create model\n",
    "conv_op = nn.Conv3d\n",
    "dropout_op = nn.Dropout3d\n",
    "norm_op = nn.InstanceNorm3d\n",
    "conv_per_stage = 2\n",
    "base_num_features = args['features']\n",
    "args['features'] = base_num_features\n",
    "\n",
    "norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "net_nonlin = nn.LeakyReLU\n",
    "net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "net_num_pool_op_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling']):  # (0,5)\n",
    "    net_num_pool_op_kernel_sizes.append([2, 2, 2])\n",
    "net_conv_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling'] + 1):  # (0,6)\n",
    "    net_conv_kernel_sizes.append([3, 3, 3])\n",
    "\n",
    "model = Generic_UNet(NumsInputChannel, base_num_features, NumsClass,\n",
    "                     len(net_num_pool_op_kernel_sizes),\n",
    "                     conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                     dropout_op_kwargs,\n",
    "                     net_nonlin, net_nonlin_kwargs, args['deepsupervision'], False, lambda x: x, InitWeights_He(1e-2),\n",
    "                     net_num_pool_op_kernel_sizes, net_conv_kernel_sizes, False, True, True)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "if args['resume']:\n",
    "    if os.path.isfile(args['resume']):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args['resume']))\n",
    "        checkpoint = torch.load(args['resume'], map_location='cuda:' + str(args['gpu']))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args['resume'], checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args['resume']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test condition x 83\n",
    "for k in tqdm(range(1,84)):\n",
    "    savename = 'atlastestcondition_' + str(k) \n",
    "    testlist = [k]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 10, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on other domains\n",
    "testlist = [0]\n",
    "for atlastestpath in tqdm(atlastestpaths):\n",
    "    DatafileValFoldts = atlastestpath\n",
    "    savename = 'atlastest_' + atlastestpath.split('/')[-2]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATLAS, rl_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'atlasval'\n",
    "savedckpt = atlasckpt_rl1\n",
    "patch_size = [128, 128, 128]\n",
    "testlist = [0]\n",
    "testprob = [1]\n",
    "NumsInputChannel = 1\n",
    "NumsClass = 2\n",
    "pathname = 'atlas_rl1'\n",
    "DatafileValFoldtr = None\n",
    "DatafileValFoldts = atlasvalpath\n",
    "#\n",
    "args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args['gpu'])\n",
    "# create model\n",
    "conv_op = nn.Conv3d\n",
    "dropout_op = nn.Dropout3d\n",
    "norm_op = nn.InstanceNorm3d\n",
    "conv_per_stage = 2\n",
    "base_num_features = args['features']\n",
    "args['features'] = base_num_features\n",
    "\n",
    "norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "net_nonlin = nn.LeakyReLU\n",
    "net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "net_num_pool_op_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling']):  # (0,5)\n",
    "    net_num_pool_op_kernel_sizes.append([2, 2, 2])\n",
    "net_conv_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling'] + 1):  # (0,6)\n",
    "    net_conv_kernel_sizes.append([3, 3, 3])\n",
    "\n",
    "model = Generic_UNet(NumsInputChannel, base_num_features, NumsClass,\n",
    "                     len(net_num_pool_op_kernel_sizes),\n",
    "                     conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                     dropout_op_kwargs,\n",
    "                     net_nonlin, net_nonlin_kwargs, args['deepsupervision'], False, lambda x: x, InitWeights_He(1e-2),\n",
    "                     net_num_pool_op_kernel_sizes, net_conv_kernel_sizes, False, True, True)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "if args['resume']:\n",
    "    if os.path.isfile(args['resume']):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args['resume']))\n",
    "        checkpoint = torch.load(args['resume'], map_location='cuda:' + str(args['gpu']))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args['resume'], checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args['resume']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test condition x 83\n",
    "for k in tqdm(range(1,84)):\n",
    "    savename = 'atlastestcondition_' + str(k) \n",
    "    testlist = [k]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 10, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on other domains\n",
    "testlist = [0]\n",
    "for atlastestpath in tqdm(atlastestpaths):\n",
    "    DatafileValFoldts = atlastestpath\n",
    "    savename = 'atlastest_' + atlastestpath.split('/')[-2]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATLAS, rl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'atlasval'\n",
    "savedckpt = atlasckpt_rl2\n",
    "patch_size = [128, 128, 128]\n",
    "testlist = [0]\n",
    "testprob = [1]\n",
    "NumsInputChannel = 1\n",
    "NumsClass = 2\n",
    "pathname = 'atlas_rl2'\n",
    "DatafileValFoldtr = None\n",
    "DatafileValFoldts = atlasvalpath\n",
    "#\n",
    "args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args['gpu'])\n",
    "# create model\n",
    "conv_op = nn.Conv3d\n",
    "dropout_op = nn.Dropout3d\n",
    "norm_op = nn.InstanceNorm3d\n",
    "conv_per_stage = 2\n",
    "base_num_features = args['features']\n",
    "args['features'] = base_num_features\n",
    "\n",
    "norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "net_nonlin = nn.LeakyReLU\n",
    "net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "net_num_pool_op_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling']):  # (0,5)\n",
    "    net_num_pool_op_kernel_sizes.append([2, 2, 2])\n",
    "net_conv_kernel_sizes = []\n",
    "for kiter in range(0, args['downsampling'] + 1):  # (0,6)\n",
    "    net_conv_kernel_sizes.append([3, 3, 3])\n",
    "\n",
    "model = Generic_UNet(NumsInputChannel, base_num_features, NumsClass,\n",
    "                     len(net_num_pool_op_kernel_sizes),\n",
    "                     conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                     dropout_op_kwargs,\n",
    "                     net_nonlin, net_nonlin_kwargs, args['deepsupervision'], False, lambda x: x, InitWeights_He(1e-2),\n",
    "                     net_num_pool_op_kernel_sizes, net_conv_kernel_sizes, False, True, True)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "if args['resume']:\n",
    "    if os.path.isfile(args['resume']):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args['resume']))\n",
    "        checkpoint = torch.load(args['resume'], map_location='cuda:' + str(args['gpu']))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args['resume'], checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args['resume']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test condition x 83\n",
    "for k in tqdm(range(1,84)):\n",
    "    savename = 'atlastestcondition_' + str(k) \n",
    "    testlist = [k]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 10, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on other domains\n",
    "testlist = [0]\n",
    "for atlastestpath in tqdm(atlastestpaths):\n",
    "    DatafileValFoldts = atlastestpath\n",
    "    savename = 'atlastest_' + atlastestpath.split('/')[-2]\n",
    "    args = {'resume': savedckpt, 'name': savename, 'saveresults': True, 'patch_size': patch_size, 'downsampling': 4,\n",
    "       'ttalist': testlist, 'ttalistprob': testprob, 'features': 30, 'deepsupervision': True, 'gpu': 1}\n",
    "    testmap(model, args['saveresults'], args['name'] + '/results/', pathname=pathname,\n",
    "                    ImgsegmentSize=args['patch_size'], deepsupervision=args['deepsupervision'],\n",
    "                    DatafileValFoldtr=DatafileValFoldtr, DatafileValFoldts=DatafileValFoldts, NumsClass=NumsClass,\n",
    "                    ttalist=args['ttalist'], ttalistprob=args['ttalistprob'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustseg",
   "language": "python",
   "name": "robustseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
